import asyncio
from typing import List, Optional, Union
from ragas import SingleTurnSample
from ragas.metrics import Faithfulness, AnswerRelevancy, LLMContextPrecisionWithoutReference, LLMContextRecall, AnswerCorrectness, AnswerSimilarity
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper

# Core logic: reusable for other tools
def score_faithfulness(user_input: str,
                       response: str, 
                       retrieved_contexts: Union[str, List[str]], 
                       llm: object) -> float:
    """
    Computes the faithfulness score of a response given a question and context using a specified LLM model.

    Args:
        user_input: Original question or prompt.
        response: Generated answer to evaluate.
        context: Retrieved grounding passage.
        llm: LLM object that is used as LLM-as-a-Judge.

    Returns:
        Float score between 0.0 (unfaithful) and 1.0 (fully faithful).
    """
    if isinstance(retrieved_contexts, str):
        retrieved_contexts = [retrieved_contexts]
    sample = SingleTurnSample(
        user_input=user_input,
        response=response,
        retrieved_contexts=retrieved_contexts
    )
    metric = Faithfulness(llm=LangchainLLMWrapper(llm))
    return asyncio.run(metric.single_turn_ascore(sample))


def score_answer_relevance(user_input: str,
                           response: str,
                           llm: object,
                           embedding: object,
                           strictness: int = 3) -> float:
    """
    Computes how relevant the generated answer is to the original question.

    This reference-free metric:
      1. Prompts the LLM to generate `strictness` artificial questions from `response`.
      2. Embeds each generated question and the original `user_input`.
      3. Returns the mean cosine similarity.

    Args:
        user_input: The original question or prompt.
        response:   The answer generated by the model.
        llm:        An LLM configured as the judge.
        embeddings: An embeddings model for computing similarity.
        strictness: Number of questions to generate (default: 3).

    Returns:
        A float (often in [0.0, 1.0]) indicating how directly `response`
        addresses `user_input`.
    """
    sample = SingleTurnSample(
        user_input=user_input,
        response=response
    )
    metric = AnswerRelevancy(llm=LangchainLLMWrapper(llm), embeddings=LangchainEmbeddingsWrapper(embedding), strictness=strictness)
    return asyncio.run(metric.single_turn_ascore(sample))

def score_context_precision(user_input: str,
                            response: str,
                            retrieved_contexts: Union[str, List[str]],
                            llm: object) -> float:
    """
    Computes retrieval precision without context reference

    Args:
        user_input:         The original question or prompt.
        retrieved_contexts: The list of passages retrieved by the system.
        llm:                An LLM for any LLM-based relevance judgments.
        embeddings: An embeddings model for computing similarity.

    Returns:
        A float between 0.0 and 1.0 indicating the proportion of relevant
        contexts in the top-K retrieval.
    """
    if isinstance(retrieved_contexts, str):
        retrieved_contexts = [retrieved_contexts]
    sample = SingleTurnSample(
        user_input=user_input,
        retrieved_contexts=retrieved_contexts,
        response=response
    )
    metric = LLMContextPrecisionWithoutReference(llm=LangchainLLMWrapper(llm))
    return asyncio.run(metric.single_turn_ascore(sample))

def score_context_recall(user_input: str,
                         retrieved_contexts: list[str],
                         reference_answer: str,
                         llm: object) -> float:
    """
    Computes retrieval recall: the fraction of true answer claims in
    `reference_answer` that can be inferred from `retrieved_contexts`.

    Args:
        user_input:         The original question or prompt.
        retrieved_contexts: The passages retrieved by the system.
        reference_answer:   The ground-truth answer to the question.
        llm:                An LLM for LLM-based claim verification.

    Returns:
        A float between 0.0 and 1.0 indicating how much of the true answer
        is covered by the retrieved contexts.
    """
    if isinstance(retrieved_contexts, str):
        retrieved_contexts = [retrieved_contexts]
    sample = SingleTurnSample(
        user_input=user_input,
        retrieved_contexts=retrieved_contexts,
        reference=reference_answer
    )
    metric = LLMContextRecall(llm=LangchainLLMWrapper(llm))
    return asyncio.run(metric.single_turn_ascore(sample))


def score_answer_correctness(user_input: str,
                             response: str,
                             reference_answer: str,
                             llm: object,
                             embedding: object,
                             weights: Optional[list[float]] = [0.75, 0.25]) -> float:
    """
    Computes the Answer Correctness score by combining:
      1. Factual overlap (precision/recall/F1) of claims in `response` vs. `ground_truth`.
      2. Semantic similarity between `response` and `ground_truth`.

    Args:
        user_input:  The original question or prompt.
        response:    The answer generated by the model.
        ground_truth:The reference answer for correctness evaluation.
        llm:         An LLM for both claim classification and semantic scoring.
        weights:     Two‚Äêelement list [w_factual, w_semantic] (default [0.75, 0.25]).

    Returns:
        A float between 0.0 and 1.0 indicating correctness.
    """
    
    sample = SingleTurnSample(
        user_input=user_input,
        response=response,
        reference=reference_answer
    )
    sub_metric = AnswerSimilarity(embeddings=LangchainEmbeddingsWrapper(embedding))
    metric = AnswerCorrectness(llm=LangchainLLMWrapper(llm), answer_similarity=sub_metric, weights=weights)
    return asyncio.run(metric.single_turn_ascore(sample))